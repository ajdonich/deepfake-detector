{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, random, time\n",
    "import psycopg2, json\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# For managing relative imports from notebook\n",
    "if '..' not in sys.path: sys.path.append('..')\n",
    "\n",
    "import config.config as dfc\n",
    "import deepfake.dfutillib as df\n",
    "import deepfake.postgresdb as pgdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "PostgreSQL version:\n",
      "  ('PostgreSQL 11.6 on x86_64-pc-linux-gnu, compiled by gcc (GCC) 4.8.3 20140911 (Red Hat 4.8.3-9), 64-bit',)\n"
     ]
    }
   ],
   "source": [
    "# Validate database connection to dfc.DATABASE\n",
    "with pgdb.PostgreSqlHandle(verbose=True): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition 0: 1334 valid videos, parse time: 0.057 sec\n",
      "Partition 1: 1699 valid videos, parse time: 0.073 sec\n",
      "Partition 2: 1748 valid videos, parse time: 0.071 sec\n",
      "Partition 3: 1455 valid videos, parse time: 0.059 sec\n",
      "Partition 4: 1701 valid videos, parse time: 0.070 sec\n",
      "Partition 5: 2483 valid videos, parse time: 0.100 sec\n",
      "Partition 6: 3464 valid videos, parse time: 0.141 sec\n",
      "Partition 7: 2473 valid videos, parse time: 0.119 sec\n",
      "Partition 8: 1816 valid videos, parse time: 0.075 sec\n",
      "Partition 9: 1736 valid videos, parse time: 0.071 sec\n",
      "Partition 10: 3192 valid videos, parse time: 0.130 sec\n",
      "Partition 11: 2118 valid videos, parse time: 0.086 sec\n",
      "Partition 12: 2225 valid videos, parse time: 0.090 sec\n",
      "Partition 13: 3694 valid videos, parse time: 0.152 sec\n",
      "Partition 14: 2464 valid videos, parse time: 0.098 sec\n",
      "Partition 15: 2273 valid videos, parse time: 0.090 sec\n",
      "Partition 16: 2061 valid videos, parse time: 0.083 sec\n",
      "Partition 17: 2430 valid videos, parse time: 0.096 sec\n",
      "Partition 18: 2683 valid videos, parse time: 0.108 sec\n",
      "Partition 19: 2752 valid videos, parse time: 0.111 sec\n",
      "Partition 20: 2154 valid videos, parse time: 0.086 sec\n",
      "Partition 21: 2268 valid videos, parse time: 0.118 sec\n",
      "Partition 22: 2409 valid videos, parse time: 0.098 sec\n",
      "Partition 23: 2410 valid videos, parse time: 0.097 sec\n",
      "Partition 24: 2786 valid videos, parse time: 0.113 sec\n",
      "Partition 25: 2546 valid videos, parse time: 0.102 sec\n",
      "Partition 26: 2433 valid videos, parse time: 0.098 sec\n",
      "Partition 27: 2353 valid videos, parse time: 0.093 sec\n",
      "Partition 28: 2085 valid videos, parse time: 0.084 sec\n",
      "Partition 29: 2557 valid videos, parse time: 0.101 sec\n",
      "Partition 30: 2236 valid videos, parse time: 0.088 sec\n",
      "Partition 31: 2470 valid videos, parse time: 0.098 sec\n",
      "Partition 32: 2356 valid videos, parse time: 0.093 sec\n",
      "Partition 33: 2274 valid videos, parse time: 0.092 sec\n",
      "Partition 34: 2658 valid videos, parse time: 0.108 sec\n",
      "Partition 35: 2535 valid videos, parse time: 0.141 sec\n",
      "Partition 36: 2339 valid videos, parse time: 0.096 sec\n",
      "Partition 37: 2655 valid videos, parse time: 0.108 sec\n",
      "Partition 38: 2477 valid videos, parse time: 0.105 sec\n",
      "Partition 39: 2556 valid videos, parse time: 0.110 sec\n",
      "Partition 40: 2420 valid videos, parse time: 0.102 sec\n",
      "Partition 41: 2222 valid videos, parse time: 0.093 sec\n",
      "Partition 42: 2384 valid videos, parse time: 0.101 sec\n",
      "Partition 43: 2546 valid videos, parse time: 0.108 sec\n",
      "Partition 44: 2665 valid videos, parse time: 0.113 sec\n",
      "Partition 45: 2346 valid videos, parse time: 0.099 sec\n",
      "Partition 46: 2202 valid videos, parse time: 0.093 sec\n",
      "Partition 47: 2406 valid videos, parse time: 0.103 sec\n",
      "Partition 48: 2463 valid videos, parse time: 0.105 sec\n",
      "Partition 49: 3134 valid videos, parse time: 0.135 sec\n",
      "\n",
      "Total dataset:\n",
      "  107232 training videos\n",
      "  11914 validation videos\n",
      "\n",
      "Assigning epoch video-blocks...\n",
      "  595 epoch video-blocks assigned\n",
      "\n",
      "Remaining back-fill videos:\n",
      "  132 training videos\n",
      "  14 validation videos\n",
      "\n",
      "Attempting database insert of:\n",
      "  107100 training videos\n",
      "  11900 validation videos\n",
      "  146 back-fill videos\n",
      "\n",
      "\n",
      "Commencing database initialization...\n",
      "Database initialization complete.\n",
      "\n",
      "Commencing database population...\n",
      "Database population complete.\n",
      "\n",
      "CPU times: user 6.15 s, sys: 4.44 s, total: 10.6 s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# This function reads each partition's metadata.json file, compiles a correpsonding \n",
    "# list of all videos, split into order-randomized training and validation sets,\n",
    "# then assigns these to epoch blocks and inserts everything into the database.\n",
    "\n",
    "def create_videos_data(istart, istop=None, validation_split=0.1, epochsz=200):\n",
    "#{\n",
    "    # Like range args\n",
    "    if istop is None: istart, istop = 0, istart\n",
    "\n",
    "    vtrains, vvalids = [],[]\n",
    "    for i in range(istart, istop):\n",
    "    #{\n",
    "        vpart, initial = [], time.time()\n",
    "        try:\n",
    "            # Store all valid tuples from the partition metadata file\n",
    "            with open(f\"{df.traindir(i)}/metadata.json\") as jsonfile:\n",
    "            #{\n",
    "                metadata = json.load(jsonfile)\n",
    "                for vidname, meta in metadata.items():\n",
    "                #{\n",
    "                    if df.file_exists(f\"{df.traindir(i)}/{vidname}\"):\n",
    "                        vtup = pgdb.VideoTuple(vidname=vidname, partition=i, label=meta['label'])\n",
    "                        if meta['label'] == 'REAL': vpart.append(vtup) \n",
    "                        elif df.file_exists(f\"{df.traindir(i)}/{meta['original']}\"):\n",
    "                            vtup.origname = meta['original']\n",
    "                            vpart.append(vtup)\n",
    "                #}\n",
    "            #}\n",
    "        except PermissionError as err: print(\"ERROR:\", err)\n",
    "\n",
    "        # Randomly select a validation subset\n",
    "        nvalids = round(validation_split*len(vpart))\n",
    "        vindices = set(random.sample(range(len(vpart)), nvalids))\n",
    "\n",
    "        # Separate into respective split\n",
    "        for j in range(len(vpart)):\n",
    "        #{\n",
    "            if j in vindices:\n",
    "                vpart[j].split = \"validate\"\n",
    "                vvalids.append(vpart[j])\n",
    "            else:\n",
    "                vpart[j].split = \"train\"\n",
    "                vtrains.append(vpart[j])\n",
    "        #}\n",
    "        \n",
    "        print((f\"Partition {i}: {len(vpart)} valid videos, \"\n",
    "               f\"parse time: {time.time()-initial:.3f} sec\"))\n",
    "    #}\n",
    "\n",
    "    print(f\"\\nTotal dataset:\")\n",
    "    print(f\"  {len(vtrains)} training videos\")\n",
    "    print(f\"  {len(vvalids)} validation videos\")\n",
    "    print(\"\\nAssigning epoch video-blocks...\")\n",
    "    \n",
    "    # Randomize video orders\n",
    "    np.random.shuffle(vtrains)\n",
    "    np.random.shuffle(vvalids)\n",
    "\n",
    "    # Init step sizes and create epoch blocks\n",
    "    nvalids = int(epochsz*validation_split)    \n",
    "    rgt = range(0, len(vtrains), epochsz - nvalids)\n",
    "    rgv = range(0, len(vvalids), nvalids)\n",
    "    \n",
    "    for blkid, (ti, vi) in enumerate(zip(rgt, rgv)):\n",
    "        for vtup in vtrains[ti:ti+epochsz-nvalids]: vtup.blk_id = blkid\n",
    "        for vtup in vvalids[vi:vi+nvalids]: vtup.blk_id = blkid\n",
    "    print(f\"  {blkid} epoch video-blocks assigned\")\n",
    "\n",
    "    # Save straggler remainders to back-fill unreadable video\n",
    "    print(f\"\\nRemaining back-fill videos:\")\n",
    "    print(f\"  {len(vtrains[ti:])} training videos\")\n",
    "    print(f\"  {len(vvalids[vi:])} validation videos\")\n",
    "    \n",
    "    for vtup in vtrains[ti:]: vtup.blk_id = -1\n",
    "    for vtup in vvalids[vi:]: vtup.blk_id = -1\n",
    "    \n",
    "    # Insert epoch video-blocks into DB\n",
    "    print(f\"\\nAttempting database insert of:\")\n",
    "    print(f\"  {len(vtrains[:ti])} training videos\")\n",
    "    print(f\"  {len(vvalids[:vi])} validation videos\")\n",
    "    print(f\"  {len(vtrains[ti:])+len(vvalids[vi:])} back-fill videos\\n\")\n",
    "        \n",
    "    with pgdb.PostgreSqlHandle() as db_handle:\n",
    "        if not db_handle.initialize_database(): print(\"Populate aborted\")\n",
    "        else: db_handle.populate_database(vtrains, vvalids)\n",
    "#}\n",
    "               \n",
    "\n",
    "#create_videos_data(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLoaderID: 139991405383504-train, loading blk_id: 479\n",
      "/home/ec2-user/SageMaker/ebs/deepfake-detect-datalake/dfdc_frames_part_6/jbucifddgs\n",
      "/home/ec2-user/SageMaker/ebs/deepfake-detect-datalake/dfdc_frames_part_38/ijgmcbwkjy\n",
      "/home/ec2-user/SageMaker/ebs/deepfake-detect-datalake/dfdc_frames_part_16/cspadzkkxy\n",
      "/home/ec2-user/SageMaker/ebs/deepfake-detect-datalake/dfdc_frames_part_47/gqopkqbkfc\n",
      "/home/ec2-user/SageMaker/ebs/deepfake-detect-datalake/dfdc_frames_part_31/vrrtdmetws\n",
      "/home/ec2-user/SageMaker/ebs/deepfake-detect-datalake/dfdc_frames_part_24/uftrzkegbd\n",
      "/home/ec2-user/SageMaker/ebs/deepfake-detect-datalake/dfdc_frames_part_24/aaoyvnkeyo\n",
      "/home/ec2-user/SageMaker/ebs/deepfake-detect-datalake/dfdc_frames_part_11/zccgqwyjjf\n",
      "/home/ec2-user/SageMaker/ebs/deepfake-detect-datalake/dfdc_frames_part_31/iqebgcigjj\n",
      "/home/ec2-user/SageMaker/ebs/deepfake-detect-datalake/dfdc_frames_part_18/cecqflguyc\n",
      "/home/ec2-user/SageMaker/ebs/deepfake-detect-datalake/dfdc_frames_part_20/znclzrxipl\n",
      "/home/ec2-user/SageMaker/ebs/deepfake-detect-datalake/dfdc_frames_part_33/dklkqoaewo\n",
      "/home/ec2-user/SageMaker/ebs/deepfake-detect-datalake/dfdc_frames_part_40/dlckdleyaj\n",
      "/home/ec2-user/SageMaker/ebs/deepfake-detect-datalake/dfdc_frames_part_18/zcjyhmcpsv\n",
      "/home/ec2-user/SageMaker/ebs/deepfake-detect-datalake/dfdc_frames_part_25/bshvtgcqnu\n",
      "/home/ec2-user/SageMaker/ebs/deepfake-detect-datalake/dfdc_frames_part_21/hybvuhzfbd\n",
      "/home/ec2-user/SageMaker/ebs/deepfake-detect-datalake/dfdc_frames_part_43/etphkpokgh\n",
      "/home/ec2-user/SageMaker/ebs/deepfake-detect-datalake/dfdc_frames_part_25/qwilmyiskx\n",
      "/home/ec2-user/SageMaker/ebs/deepfake-detect-datalake/dfdc_frames_part_48/fpqcsldjwl\n",
      "/home/ec2-user/SageMaker/ebs/deepfake-detect-datalake/dfdc_frames_part_29/fbvvheoquw\n",
      "/home/ec2-user/SageMaker/ebs/deepfake-detect-datalake/dfdc_frames_part_18/nkedosswxb\n",
      "/home/ec2-user/SageMaker/ebs/deepfake-detect-datalake/dfdc_frames_part_22/prxibpoybd\n",
      "/home/ec2-user/SageMaker/ebs/deepfake-detect-datalake/dfdc_frames_part_13/vlwylbdtqv\n",
      "/home/ec2-user/SageMaker/ebs/deepfake-detect-datalake/dfdc_frames_part_49/bbpjgsfveo\n",
      "/home/ec2-user/SageMaker/ebs/deepfake-detect-datalake/dfdc_frames_part_36/sxbfdmebrp\n",
      "/home/ec2-user/SageMaker/ebs/deepfake-detect-datalake/dfdc_frames_part_28/zuporxcref\n",
      "/home/ec2-user/SageMaker/ebs/deepfake-detect-datalake/dfdc_frames_part_36/etodejdqoj\n",
      "/home/ec2-user/SageMaker/ebs/deepfake-detect-datalake/dfdc_frames_part_15/dhzmyolony\n",
      "/home/ec2-user/SageMaker/ebs/deepfake-detect-datalake/dfdc_frames_part_45/ihszkmcwvw\n",
      "/home/ec2-user/SageMaker/ebs/deepfake-detect-datalake/dfdc_frames_part_19/stxpjcspgw\n",
      "/home/ec2-user/SageMaker/ebs/deepfake-detect-datalake/dfdc_frames_part_7/hiadoidirz\n",
      "/home/ec2-user/SageMaker/ebs/deepfake-detect-datalake/dfdc_frames_part_46/vfvuuhbgny\n",
      "/home/ec2-user/SageMaker/ebs/deepfake-detect-datalake/dfdc_frames_part_49/apfwbpnetp\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'flatten'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-c546ee100e9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgtor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgtor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/SageMaker/kaggle-deepfake-detection/deepfake/modelutil.py\u001b[0m in \u001b[0;36mlazy_loader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0myloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loadtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{df.fakerdir(partition)}/{videoname[:-4]}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mylabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'dflat_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fake_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mylabels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/kaggle-deepfake-detection/deepfake/modelutil.py\u001b[0m in \u001b[0;36m_loadtarget\u001b[0;34m(self, vfakerdir, label, nsamps, nframes, targsize)\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvfakerdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnsamps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m                     \u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{vfakerdir}/fakerframe{fidx+i}.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'flatten'"
     ]
    }
   ],
   "source": [
    "import deepfake.modelutil as mutil\n",
    "\n",
    "trloader = mutil.ModelLoader(split='train')\n",
    "gtor = trloader.lazy_loader()\n",
    "for i in range(180): next(gtor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_deepfake",
   "language": "python",
   "name": "deepfake"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
