{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os, time, datetime\n",
    "\n",
    "import psutil\n",
    "process = psutil.Process(os.getpid())\n",
    "print(f\"Available memory: {int(psutil.virtual_memory().available / 1024 / 1024)} Mb\")\n",
    "\n",
    "# nbytes = process.memory_info().rss # bytes\n",
    "# print(f\"Process memory: {nbytes} bytes ({nbytes / 1024 / 1024} Mb)\") \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(f\"Using Tensorflow v{tf.__version__}\")\n",
    "\n",
    "# For managing relative imports from notebook\n",
    "if '..' not in sys.path: sys.path.append('..')\n",
    "\n",
    "import config.config as dfc\n",
    "import deepfake.dfutillib as df\n",
    "import deepfake.modelutil as mutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- Model Architecture -------------------------\n",
    "\n",
    "def create_encdec_network():\n",
    "#{\n",
    "    model = None\n",
    "\n",
    "    # Layer #0: Input\n",
    "    frame_input = keras.layers.Input(shape=(360, 640, 3))\n",
    "\n",
    "    # Layer #1: First set of convolutional layers\n",
    "    X = keras.layers.Conv2D(filters=32, kernel_size=(11,11), strides=(2,4))(frame_input)\n",
    "    X = keras.layers.MaxPooling2D()(X)\n",
    "    \n",
    "    # Layer #2: Second set of convolutional layers\n",
    "    X = keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1))(X)\n",
    "    X = keras.layers.MaxPooling2D()(X)\n",
    "    \n",
    "    # Layer #3: Third set of convolutional layers\n",
    "    X = keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1))(X)\n",
    "    X = keras.layers.MaxPooling2D()(X)\n",
    "    \n",
    "    # Layer #4-5: Fully connected layers\n",
    "    X_flat = keras.layers.Flatten()(X)\n",
    "    X = keras.layers.Dense(720, activation = \"relu\")(X_flat)\n",
    "    X = keras.layers.Dense(720, activation = \"relu\")(X)\n",
    "    X = keras.layers.Concatenate(axis=1)([X, X_flat])\n",
    "    X = keras.layers.Reshape((20,18,130))(X)\n",
    "    \n",
    "    # Layer #6: First set of deconvolutional layers\n",
    "    X = keras.layers.UpSampling2D()(X)\n",
    "    X = keras.layers.Conv2DTranspose(filters=64, kernel_size=(3,3), strides=(1,1))(X)\n",
    "\n",
    "    # Layer #7: Second set of deconvolutional layers\n",
    "    X = keras.layers.UpSampling2D()(X)\n",
    "    X = keras.layers.Conv2DTranspose(filters=32, kernel_size=(3,3), strides=(1,1))(X)\n",
    "\n",
    "    # Layer #8: Last deconvolution to diff image output\n",
    "    X = keras.layers.UpSampling2D()(X)\n",
    "    diff_output = keras.layers.Conv2DTranspose(filters=3, kernel_size=(11,11), strides=(2,4))(X)\n",
    "        \n",
    "    # Layer #9-10: Final fully connected to binary REAL/FAKE class\n",
    "    X = keras.layers.MaxPooling2D(pool_size=(6, 6))(diff_output)\n",
    "    X = keras.layers.Flatten()(X)\n",
    "    X = keras.layers.Dense(512, activation = \"relu\")(X)\n",
    "    X = keras.layers.Dense(512, activation = \"relu\")(X)\n",
    "\n",
    "    # Output layers\n",
    "    dflat_output = keras.layers.Flatten(name='dflat_output')(diff_output)\n",
    "    fake_output = keras.layers.Dense(1, activation = \"sigmoid\", name='fake_output')(X)\n",
    "    \n",
    "    model = keras.models.Model(inputs = frame_input, outputs = [dflat_output, fake_output])\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- Model Instantiation -------------------------\n",
    "\n",
    "model = create_encdec_network()\n",
    "model.compile(optimizer=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, decay=1e-6), \n",
    "              loss_weights=[1.0, 0.2], metrics=['accuracy', 'binary_accuracy'],\n",
    "              loss={'dflat_output': tf.keras.losses.MeanSquaredError(), \n",
    "                    'fake_output': tf.keras.losses.BinaryCrossentropy()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- Loaders Disk -> Model -------------------------\n",
    "    \n",
    "# Model data loaders\n",
    "trloader = mutil.ModelLoader(split='train')\n",
    "vdloader = mutil.ModelLoader(split='validate')\n",
    "\n",
    "# Data shapes\n",
    "inshape, labelshape = (None, 360, 640, 3), (None, 1)\n",
    "imgoutshape = (None, dfc.TARGETSZ[0]*dfc.TARGETSZ[1]*3)\n",
    "\n",
    "# TF Dataset wrappers for data loaders\n",
    "trdataset = tf.data.Dataset.from_generator(generator=trloader.lazy_loader, \n",
    "    output_types=(tf.uint8, {'dflat_output': tf.uint8, 'fake_output': tf.uint8}),\n",
    "    output_shapes=(inshape, {'dflat_output': imgoutshape, 'fake_output': labelshape}))\n",
    "\n",
    "vddataset = tf.data.Dataset.from_generator(generator=vdloader.lazy_loader, \n",
    "    output_types=(tf.uint8, {'dflat_output': tf.uint8, 'fake_output': tf.uint8}),\n",
    "    output_shapes=(inshape, {'dflat_output': imgoutshape, 'fake_output': labelshape}))\n",
    "\n",
    "# ------------------------- Callbacks Model -> Disk/Db -------------------------\n",
    "\n",
    "# Timestamped logging/model directories\n",
    "outdir = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "tboarddir = f\"{dfc.TBOARD_LOG}/{outdir}\"\n",
    "modeldir = f'{dfc.MODEL_STORE}/{outdir}'\n",
    "if not os.path.isdir(tboarddir): os.mkdir(tboarddir)\n",
    "if not os.path.isdir(modeldir): os.mkdir(modeldir)\n",
    "\n",
    "# Custom callback\n",
    "epwrapdb_cb = mutil.PgdbWrapupCb(model)\n",
    "\n",
    "# TF built-in callbacks\n",
    "tboard_cb = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=tboarddir, histogram_freq=1, write_graph=True, \n",
    "    write_images=True, update_freq=60, profile_batch=7)\n",
    "\n",
    "savemodel_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=(f'{modeldir}/' + 'model.{epoch:02d}-{val_loss:.2f}.hdf5'), \n",
    "    monitor='val_loss', save_best_only=False, save_freq='epoch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- Training -------------------------\n",
    "\n",
    "history = model.fit(\n",
    "    x=trdataset, steps_per_epoch=trloader.epochsz,\n",
    "    validation_data=vddataset, validation_steps=vdloader.epochsz,\n",
    "    callbacks=[tboard_cb, savemodel_cb, epwrapdb_cb],\n",
    "    initial_epoch=0, verbose=2, epochs=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_deepfake",
   "language": "python",
   "name": "deepfake"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
