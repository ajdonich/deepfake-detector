{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deepfake Data Preprocessor\n",
    "\n",
    "This Notebook is for preprocessing the training data, i.e. (currently anyway) creating difference-blend-mode image files   \n",
    "for every frame of the faked video, plus a final \"fakerprint\" image (see comments below). You should be able to preprocess  \n",
    "kaggle's little sample dataset in only like 20 minutes. This video player: https://darbyjohnston.github.io/DJV/ can play  \n",
    "the JPG difference-image sequences as if they were a video if you want (Premiere can do this too, but not Quicktime).\n",
    "\n",
    "Make sure to correctly set the **DATA_LAKE** below before preprocessing (and **run_sample_data** flag if apropos). \n",
    "\n",
    "#### Main Function Table of Contents:\n",
    "+ **summarize_data()** - Just has a tertiary look at the dataset and prints out some metrics.\n",
    "+ **create_fakerframes_cv2()** - Creates the actual difference and fakerprint image files.\n",
    "+ **preprocess_data()** - Orchestrates calls to faked_video_pairs() and create_fakerframes_cv2() on the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os, re, time\n",
    "import functools\n",
    "import cv2, json\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "\n",
    "# For managing relative imports from notebook\n",
    "if '..' not in sys.path: sys.path.append('..')\n",
    "\n",
    "import config.config as dfc\n",
    "import deepfake.dfutillib as df\n",
    "\n",
    "from deepfake.preprocess_service import Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odd FPS of 10 in video: /Volumes/My Book/deepfake-detect-datalake/dfdc_train_part_27/eypudhbdbp.mp4\n",
      "Preprocessing epoch block 121:\n",
      "  Processed 10 videos, running average time/pair: 2.11 sec\n",
      "Odd FPS of 24 in video: /Volumes/My Book/deepfake-detect-datalake/dfdc_train_part_6/djbfwqsvsb.mp4\n",
      "  Processed 20 videos, running average time/pair: 2.14 sec\n",
      "  Processed 30 videos, running average time/pair: 2.14 sec\n",
      "  Processed 40 videos, running average time/pair: 2.04 sec\n",
      "  Processed 50 videos, running average time/pair: 2.14 sec\n",
      "  Processed 60 videos, running average time/pair: 2.02 sec\n",
      "  Processed 70 videos, running average time/pair: 2.06 sec\n",
      "Odd FPS of 24 in video: /Volumes/My Book/deepfake-detect-datalake/dfdc_train_part_15/xbndsesqdq.mp4\n",
      "  Processed 80 videos, running average time/pair: 1.96 sec\n",
      "  Processed 90 videos, running average time/pair: 1.83 sec\n",
      "  Processed 100 videos, running average time/pair: 1.93 sec\n",
      "Odd FPS of 10 in video: /Volumes/My Book/deepfake-detect-datalake/dfdc_train_part_27/eypudhbdbp.mp4\n",
      "  Processed 110 videos, running average time/pair: 2.03 sec\n",
      "  Processed 120 videos, running average time/pair: 2.07 sec\n",
      "  Processed 130 videos, running average time/pair: 2.00 sec\n",
      "  Processed 140 videos, running average time/pair: 1.92 sec\n",
      "  Processed 150 videos, running average time/pair: 2.13 sec\n",
      "Odd FPS of 24 in video: /Volumes/My Book/deepfake-detect-datalake/dfdc_train_part_24/mttsurxjue.mp4\n",
      "Odd FPS of 24 in video: /Volumes/My Book/deepfake-detect-datalake/dfdc_train_part_6/ysvuiysbns.mp4\n",
      "  Processed 160 videos, running average time/pair: 2.05 sec\n",
      "Odd FPS of 15 in video: /Volumes/My Book/deepfake-detect-datalake/dfdc_train_part_27/bcqgoxqhjc.mp4\n",
      "  Total process time: 5.76 min\n"
     ]
    }
   ],
   "source": [
    "Preprocessor().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This fcn takes just an initial glance at the video and metadata\n",
    "# in the training set and prints out some informational metrics.\n",
    "def summarize_data(istart, istop=None, netsum=True, verbose=False):\n",
    "#{\n",
    "    # Like range args\n",
    "    if istop is None:\n",
    "        istart, istop = 0, istart\n",
    "\n",
    "    summation = []\n",
    "    for i in range(istart, istop):\n",
    "    #{\n",
    "        try:\n",
    "        #{\n",
    "            numvids, numtrain, vidsfounds, numfakes, origfound = 0,0,0,0,0\n",
    "            with open(f\"{df.traindir(i)}/metadata.json\") as jsonfile:\n",
    "            #{\n",
    "                metadata = json.load(jsonfile)\n",
    "                for vidname, meta in metadata.items():\n",
    "                #{\n",
    "                    vname = f\"{df.traindir(i)}/{vidname}\"\n",
    "                    numvids += 1\n",
    "\n",
    "                    if meta['split'] == 'train': numtrain += 1\n",
    "                    if df.file_exists(vname): vidsfounds += 1\n",
    "\n",
    "                    if (meta['label'] == 'FAKE'):\n",
    "                        oname = f\"{df.traindir(i)}/{meta['original']}\"\n",
    "                        if df.file_exists(oname): origfound += 1\n",
    "                        numfakes += 1\n",
    "                #}\n",
    "            #}\n",
    "        #}\n",
    "        except PermissionError as err: print(\"ERROR:\", err)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Partition: {df.trainpart(i)}:\")\n",
    "            print(f\"  Numb of primary video meta-references/train split: {numvids}/{numtrain}\")\n",
    "            print(f\"  Numb of actual primary videos files found on disk: {vidsfounds}\")\n",
    "            print(f\"  Numb of fake/original meta-pairs: {numfakes}\")\n",
    "            print(f\"  Numb of actual video pairs found on disk: {origfound}\")\n",
    "            \n",
    "        if (numvids != vidsfounds) or (numvids != numtrain) or (numfakes != origfound):\n",
    "            print(f\"  DISCREPENCY found in partition {df.trainpart(i)}\")\n",
    "            \n",
    "        if netsum: summation.append((numvids, numtrain, vidsfounds, numfakes, origfound))\n",
    "    #}\n",
    "    \n",
    "    if netsum:\n",
    "    #{\n",
    "        numvids, numtrain, vidsfounds, numfakes, origfound = functools.reduce(\n",
    "            lambda st1, st2: (st1[0]+st2[0], st1[1]+st2[1], st1[2]+st2[2], \n",
    "                              st1[3]+st2[3], st1[4]+st2[4]), summation)\n",
    "        \n",
    "        print(f\"\\nNet dataset summary:\")\n",
    "        print(f\"  Numb of primary video meta-references/train split: {numvids}/{numtrain}\")\n",
    "        print(f\"  Numb of actual primary videos files found on disk: {vidsfounds}\")\n",
    "        print(f\"  Numb of fake/original meta-pairs: {numfakes}\")\n",
    "        print(f\"  Numb of actual video pairs found on disk: {origfound}\\n\")\n",
    "    #}\n",
    "#}\n",
    "\n",
    "if dfc.DATA_SOURCE == 'production':\n",
    "#{\n",
    "    summarize_data(50, verbose=False)\n",
    "\n",
    "    # Partitions 18 and 35 appear slightly incomplete.\n",
    "    # summarize_data(18, 19, netsum=False, verbose=True)\n",
    "    # summarize_data(35, 36, netsum=False, verbose=True)\n",
    "#}\n",
    "elif dfc.DATA_SOURCE == 'sample': \n",
    "    summarize_data(1, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Generates video pairs from metadata file, defines a datapath per\n",
    "# pair, and generates fakerframes and fakerprint for that pair.\n",
    "def preprocess_data(istart=1, istop=None, batchsz=10):\n",
    "#{\n",
    "    if istop is None: istart, istop = 0, istart\n",
    "\n",
    "    batchtimes, batchnum = [], 1\n",
    "    for i in range(istart, istop):\n",
    "    #{\n",
    "        parttime = time.time()\n",
    "        fpairs = df.faked_video_pairs(i)\n",
    "        if not os.path.isdir(df.fakerdir(i)): os.mkdir(df.fakerdir(i))\n",
    "        print(f\"Preprocessing {len(fpairs)} video pairs in partition {df.trainpart(i)}:\")\n",
    "        for j, pc_pair in enumerate(fpairs):\n",
    "        #{\n",
    "            # This is some finagled code to pickup somewhere mid-partition\n",
    "            #if re.split(r'[/.]', pc_pair[0])[-2] == 'wmoigsbnem': pickup = True\n",
    "            #if not pickup: continue\n",
    "        \n",
    "            batchtimes.append(time.time())\n",
    "            datapath = f\"{df.fakerdir(i)}/{re.split(r'[/.]', pc_pair[0])[-2]}\"\n",
    "            if not os.path.isdir(datapath): os.mkdir(datapath)\n",
    "            df.create_diff_frames(pc_pair[0], pc_pair[1], datapath)\n",
    "            \n",
    "            batchtimes[-1] = time.time() - batchtimes[-1]\n",
    "            if len(batchtimes) == batchsz:\n",
    "                print(f\"  Average preprocess time per pair for batch {batchnum}: {np.average(batchtimes):.2f} sec\")\n",
    "                batchnum += 1; batchtimes = []\n",
    "        #}\n",
    "        print(f\"  Total partition {df.trainpart(i)} preprocessing time: {(time.time()-parttime):.2f} sec\")\n",
    "    #}\n",
    "#}\n",
    "\n",
    "if dfc.DATA_SOURCE == 'sample':\n",
    "    preprocess_data()\n",
    "\n",
    "elif dfc.DATA_SOURCE == 'production': \n",
    "#{\n",
    "    # With no arguments, preprocesses just the first partition (1334 videos). \n",
    "    # On my iMac, this averaged ~28 sec/video (or 10.5 hrs total).\n",
    "    preprocess_data()\n",
    "#}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just copies all the fakerprints into a single \n",
    "# for directory testing/debugging purposes\n",
    "\n",
    "import shutil\n",
    "\n",
    "dirlist = !ls -tr1 {df.fakerdir()}\n",
    "for i, dfile in enumerate(dirlist): \n",
    "    shutil.copyfile(f\"{df.fakerdir()}/{dfile}/fakerprint.jpg\",\n",
    "                    f\"{df.fakerdir()}/../fakerprints/fakerprint{i}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
